{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manitoba Premier Scott Moe speech text analysis\n",
    "\n",
    "*February 1, 2022*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a bit of code to count the number of phrases from the transcript of a speech by Moe. Let's count how many bigrams (two word phrases) that he uses. We'll import a number of libraries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams             # Used to split our text into ngrams (phrases of n length).\n",
    "from collections import Counter     # Used to count ngram occurences after we split them up.\n",
    "import pandas as pd                 # A standard data analysis library.\n",
    "import string                       # Used to remove all punctuation from our text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will read in the text to be processed from a file in our raw data folder. We'll also take this opportunity to strip out punctuation, make everything lowercase, and remove extra spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well good morning everyone and thank you for joining us here this morning last september during what\n"
     ]
    }
   ],
   "source": [
    "with open('../raw/RAW 2022 MOESPEECH.txt', 'r') as file:\n",
    "    text = (file\n",
    "            .read()\n",
    "            .rstrip()\n",
    "            .translate(str.maketrans('', '', string.punctuation))\n",
    "            .lower()\n",
    "            )\n",
    "    \n",
    "print(text[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a few bits of setup. We're going to create an empty list that we'll use to hold our ngrams. We'll also define a small function that will convert a tuple (the output of the ngrams library we're using) to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An empty list to collect all of the phrases for counting.\n",
    "all_bigrams = []\n",
    "\n",
    "# A small function that will convert a tuple to a string.\n",
    "def convertTuple(tup):\n",
    "    str = ' '.join(tup)\n",
    "    return str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the fun stuff. We'll use n to define how many words we want in each ngram. In this example, I've set it to 3. Then we use the ngrams library's main method to split the text file we read in earlier, and our above-defined function to convert all the tuples into strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well good morning', 'good morning everyone', 'morning everyone and', 'everyone and thank', 'and thank you']\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "\n",
    "bigrams = ngrams(text.split(), n)\n",
    "\n",
    "for gram in bigrams:\n",
    "    all_bigrams.append(convertTuple(gram))\n",
    "    \n",
    "print(all_bigrams[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use a library defined above to count occurences of ngrams in the list we just made. It spits out a Python dictionary that we can then read into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>its time for</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proof of vaccination</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public health orders</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whether or not</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in this province</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Count\n",
       "its time for             28\n",
       "proof of vaccination     28\n",
       "public health orders     28\n",
       "whether or not           24\n",
       "in this province         24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phrase_counts = Counter(all_bigrams)\n",
    "\n",
    "df = (pd.DataFrame(phrase_counts, index=[\"Count\"])\n",
    "      .transpose()\n",
    "      .sort_values(by=\"Count\", ascending=False)\n",
    "      )\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty quick and dirty way of doing this. You may want to remove certain phrases from this (for instance, remove the word \"and\" before you split into ngrams.). But from here, you can turn this into a word cloud or whatever else you like!\n",
    "\n",
    "\\-30\\-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73de8b438f32372771bda1aa2e3d2689a59747422210df3e3470a45f58c477e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
